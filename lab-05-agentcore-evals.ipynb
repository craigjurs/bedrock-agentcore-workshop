{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Lab 5: AgentCore Evaluations - Online Evaluation for Customer Support Agent\n",
    "\n",
    "### Overview\n",
    "\n",
    "This lab demonstrates how to use AgentCore Evaluations to continuously monitor your production customer support agent from Lab 4. You'll configure online evaluation to automatically assess agent performance in real-time as customers interact with it.\n",
    "\n",
    "**Workshop Journey:**\n",
    "\n",
    "- **Lab 1 (Done):** Create Agent Prototype - Built a functional customer support agent\n",
    "- **Lab 2 (Done):** Enhance with Memory - Added conversation context and personalization\n",
    "- **Lab 3 (Done):** Scale with Gateway & Identity - Shared tools across agents securely\n",
    "- **Lab 4 (Done):** Deploy to Production - Used AgentCore Runtime with observability\n",
    "- **Lab 5 (Current):** Evaluate Agent Performance - Monitor quality with online evaluations\n",
    "- **Lab 6:** Build User Interface - Create a customer-facing application\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "You'll configure online evaluation with built-in evaluators, generate test interactions, and analyze quality metrics through AgentCore Observability dashboards to improve agent performance.\n",
    "\n",
    "### Online Evaluation Overview\n",
    "\n",
    "Online evaluation continuously monitors deployed agents in production, unlike on-demand evaluation which analyzes specific selected interactions. It consists of three components: session sampling with configurable rules, multiple evaluation methods (built-in or custom evaluators), and monitoring through dashboards with quality trends and low-scoring session investigation.\n",
    "\n",
    "Since your agent runs on AgentCore Runtime, AgentCore Observability automatically instruments the code and provides comprehensive logs and traces using [OTEL](https://opentelemetry.io/) instrumentation.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Complete Lab 4 to have the customer support agent deployed. You'll need AWS account access to Amazon Bedrock AgentCore with Evaluations permissions.\n",
    "\n",
    "### Architecture\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_lab5_evaluation.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "*Online evaluation automatically monitors agent interactions, applies evaluators based on sampling rules, and outputs results to CloudWatch for analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01af13-5b54-45eb-93f7-31d4d0974cce",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries and Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b7ff2f6-d0ee-4d11-8776-d9dbbc729dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Evaluation, Runtime\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from boto3.session import Session\n",
    "from IPython.display import Markdown, display\n",
    "from lab_helpers.utils import get_ssm_parameter, get_or_create_cognito_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ebd476-2e81-476c-b328-36a60d7b199d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "print(f\"Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a06e1972-6cf3-4e07-adfd-cb4981902668",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_client = Evaluation(region=region)\n",
    "runtime_client = Runtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec431f-d5bd-47a1-b945-e29692dfaf14",
   "metadata": {},
   "source": [
    "### Step 2: Retrieve Agent Information from Lab 4\n",
    "\n",
    "Retrieve the customer support agent ARN from SSM Parameter Store where it was saved during Lab 4 deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30d7001-3212-44b6-b401-ea93b8a9abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ID: customer_support_agent-v9Id4341wf\n",
      "Agent ARN: arn:aws:bedrock-agentcore:us-west-2:426068478522:runtime/customer_support_agent-v9Id4341wf\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get agent ARN from SSM parameter store (saved in Lab 4)\n",
    "    agent_arn = get_ssm_parameter(\"/app/customersupport/agentcore/runtime_arn\")\n",
    "    \n",
    "    # Extract agent ID from ARN\n",
    "    agent_id = agent_arn.split(\":\")[-1].split(\"/\")[-1]\n",
    "    \n",
    "    # Set runtime client config path\n",
    "    runtime_client._config_path = Path.cwd() / \".bedrock_agentcore.yaml\"\n",
    "    \n",
    "    print(\"Agent ID:\", agent_id)\n",
    "    print(\"Agent ARN:\", agent_arn)\n",
    "except Exception as e:\n",
    "    raise Exception(f\"\"\"Missing agent information from Lab 4. Please run lab-04-agentcore-runtime.ipynb first. Error: {str(e)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d6132-71d7-4654-9310-a61bdc435bc9",
   "metadata": {},
   "source": [
    "### Step 3: Create Online Evaluation Configuration\n",
    "\n",
    "Now let's create an online evaluation configuration for our customer support agent. We'll use built-in evaluators to assess different aspects of agent performance:\n",
    "\n",
    "- **Builtin.GoalSuccessRate** - Measures how well the agent achieves user goals\n",
    "- **Builtin.Correctness** - Evaluates factual accuracy of responses\n",
    "- **Builtin.ToolSelectionAccuracy** - Evaluates appropriate tool selection\n",
    "\n",
    "We'll set the sampling rate to 100% for demonstration purposes, but in production you might use a lower rate (e.g., 10-20%) based on your traffic volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1921ef17-43e4-4471-92b9-a0f31bd8f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating online evaluation config: customer_support_agent_eval for agent: customer_support_agent-v9Id4341wf\n",
      "Configuration: sampling_rate=100.0%, evaluators=['Builtin.GoalSuccessRate', 'Builtin.Correctness', 'Builtin.ToolSelectionAccuracy']\n",
      "Creating online evaluation config: customer_support_agent_eval for agent: customer_support_agent-v9Id4341wf\n",
      "Auto-creating execution role for config: customer_support_agent_eval\n",
      "Getting or creating evaluation execution role for config: customer_support_agent_eval\n",
      "Using AWS region: us-west-2, account ID: 426068478522\n",
      "Role name: AgentCoreEvalsSDK-us-west-2-d04ba7b68b\n",
      "Role doesn't exist, creating new evaluation execution role: AgentCoreEvalsSDK-us-west-2-d04ba7b68b\n",
      "Creating IAM role: AgentCoreEvalsSDK-us-west-2-d04ba7b68b\n",
      "‚úì Role created: arn:aws:iam::426068478522:role/AgentCoreEvalsSDK-us-west-2-d04ba7b68b\n",
      "‚úì Execution policy attached: AgentCoreEvaluationPolicy-us-west-2-d04ba7b68b\n",
      "Waiting for IAM role propagation...\n",
      "Role creation complete and ready for use with Bedrock AgentCore Evaluation\n",
      "‚úì Execution role ready: arn:aws:iam::426068478522:role/AgentCoreEvalsSDK-us-west-2-d04ba7b68b\n",
      "‚úì Online evaluation config created: customer_support_agent_eval-VuUOlc4onO\n",
      "‚úì Online evaluation config created successfully\n",
      "Config ID: customer_support_agent_eval-VuUOlc4onO\n",
      "Status: CREATING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Online evaluation configuration created!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Online evaluation configuration created!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online evaluation configuration created successfully!\n",
      "Configuration ID: customer_support_agent_eval-VuUOlc4onO\n"
     ]
    }
   ],
   "source": [
    "response = eval_client.create_online_config(\n",
    "    agent_id=agent_id,\n",
    "    config_name=\"customer_support_agent_eval\",\n",
    "    sampling_rate=100,  # Evaluate 100% of sessions for demo\n",
    "    evaluator_list=[\n",
    "        \"Builtin.GoalSuccessRate\", \n",
    "        \"Builtin.Correctness\",\n",
    "        \"Builtin.ToolSelectionAccuracy\"\n",
    "    ],\n",
    "    config_description=\"Customer support agent online evaluation\",\n",
    "    auto_create_execution_role=True\n",
    ")\n",
    "\n",
    "print(\"Online evaluation configuration created successfully!\")\n",
    "print(f\"Configuration ID: {response['onlineEvaluationConfigId']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ac193-5672-473d-a4c2-668667c1e77e",
   "metadata": {},
   "source": [
    "### Step 4: Verify Configuration Status\n",
    "\n",
    "Verify the evaluation configuration is properly created and enabled by retrieving its details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b8ee2f-f875-41a8-8226-650d1127e5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Details:\n",
      "{\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"3a6c83c6-48c4-4175-8505-22659d33f98e\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Fri, 16 Jan 2026 19:49:03 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"1052\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"3a6c83c6-48c4-4175-8505-22659d33f98e\",\n",
      "      \"x-amzn-remapped-x-amzn-requestid\": \"c4db37e5-b99a-469e-a8ec-5a32f5b05452\",\n",
      "      \"x-amzn-remapped-content-length\": \"1052\",\n",
      "      \"x-amzn-remapped-connection\": \"keep-alive\",\n",
      "      \"x-cache\": \"Miss from cloudfront\",\n",
      "      \"via\": \"1.1 11017c4db22106ac70e16ce75190a430.cloudfront.net (CloudFront)\",\n",
      "      \"x-amz-cf-id\": \"zx_R60ZSlztRplKRIMfKh3n4Y3CGdFXjGSJY6bwyYVuPtTDPjjFQXA==\",\n",
      "      \"x-amz-apigw-id\": \"XSxneEagPHcEQHQ=\",\n",
      "      \"x-amzn-trace-id\": \"Root=1-696a962f-36e8e9f62d52aaa5017acd33\",\n",
      "      \"x-amz-cf-pop\": \"HIO52-P4\",\n",
      "      \"x-amzn-remapped-date\": \"Fri, 16 Jan 2026 19:49:03 GMT\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"onlineEvaluationConfigArn\": \"arn:aws:bedrock-agentcore:us-west-2:426068478522:online-evaluation-config/customer_support_agent_eval-VuUOlc4onO\",\n",
      "  \"onlineEvaluationConfigId\": \"customer_support_agent_eval-VuUOlc4onO\",\n",
      "  \"onlineEvaluationConfigName\": \"customer_support_agent_eval\",\n",
      "  \"description\": \"Customer support agent online evaluation\",\n",
      "  \"rule\": {\n",
      "    \"samplingConfig\": {\n",
      "      \"samplingPercentage\": 100.0\n",
      "    }\n",
      "  },\n",
      "  \"dataSourceConfig\": {\n",
      "    \"cloudWatchLogs\": {\n",
      "      \"logGroupNames\": [\n",
      "        \"/aws/bedrock-agentcore/runtimes/customer_support_agent-v9Id4341wf-DEFAULT\"\n",
      "      ],\n",
      "      \"serviceNames\": [\n",
      "        \"customer_support_agent.DEFAULT\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"evaluators\": [\n",
      "    {\n",
      "      \"evaluatorId\": \"Builtin.GoalSuccessRate\"\n",
      "    },\n",
      "    {\n",
      "      \"evaluatorId\": \"Builtin.Correctness\"\n",
      "    },\n",
      "    {\n",
      "      \"evaluatorId\": \"Builtin.ToolSelectionAccuracy\"\n",
      "    }\n",
      "  ],\n",
      "  \"outputConfig\": {\n",
      "    \"cloudWatchConfig\": {\n",
      "      \"logGroupName\": \"/aws/bedrock-agentcore/evaluations/results/customer_support_agent_eval-VuUOlc4onO\"\n",
      "    }\n",
      "  },\n",
      "  \"evaluationExecutionRoleArn\": \"arn:aws:iam::426068478522:role/AgentCoreEvalsSDK-us-west-2-d04ba7b68b\",\n",
      "  \"status\": \"ACTIVE\",\n",
      "  \"executionStatus\": \"ENABLED\",\n",
      "  \"createdAt\": \"2026-01-16 19:49:03.368000+00:00\",\n",
      "  \"updatedAt\": \"2026-01-16 19:49:03.644000+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_details = eval_client.get_online_config(config_id=response['onlineEvaluationConfigId'])\n",
    "print(\"Configuration Details:\")\n",
    "print(json.dumps(config_details, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f892c-b15a-497e-a454-cb1677468725",
   "metadata": {},
   "source": [
    "### Step 5: Generate Test Interactions\n",
    "\n",
    "Invoke the customer support agent with various queries to generate traces for evaluation. Different test scenarios will demonstrate how the evaluators assess agent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f88a905-767f-49e9-9978-66ae5845343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token obtained: eyJraWQiOiJsWktuejBt...\n"
     ]
    }
   ],
   "source": [
    "# Get authentication token\n",
    "access_token = get_or_create_cognito_pool(refresh_token=True)\n",
    "print(f\"Access token obtained: {access_token['bearer_token'][:20]}...\")\n",
    "\n",
    "def invoke_agent_runtime(prompt, session_id=None):\n",
    "    \"\"\"Invoke the agent runtime using starter toolkit\"\"\"\n",
    "    if not session_id:\n",
    "        session_id = str(uuid.uuid4())\n",
    "    \n",
    "    response = runtime_client.invoke(\n",
    "        payload={\"prompt\": prompt},\n",
    "        session_id=session_id,\n",
    "        bearer_token=access_token['bearer_token']\n",
    "    )\n",
    "    \n",
    "    return response, session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b72f0-8c4b-4b27-b0ca-38c22d666cbd",
   "metadata": {},
   "source": [
    "#### Test Scenario 1: Product Information Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dbda8d0-dc8d-4793-90ed-63760b0ab094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using JWT authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: Product information request\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Based on the search results, here's what I found about the **PlayStation 5 Pro** (which appears to be the \\\"Gaming Console Pro\\\" you're referring to):\n",
       "\n",
       "## Key Specifications:\n",
       "- **All-Digital Console** - No disc drive included\n",
       "- **Advanced Ray Tracing** - Enhanced graphics capabilities\n",
       "- **4K Display Support** - Super sharp image clarity for 4K TVs\n",
       "- **High Frame Rate Gameplay** - Smooth performance for demanding games\n",
       "- **Storage**: 2TB SSD\n",
       "- **Release Date**: November 7, 2024\n",
       "\n",
       "## Pricing:\n",
       "- **Price**: $700 USD\n",
       "- **Bundle Options**: Available with two DualSense controllers and other accessories\n",
       "\n",
       "## Notable Features:\n",
       "The PS5 Pro is designed to give game creators advanced tools to enhance their games with better visuals and performance compared to the standard PS5.\n",
       "\n",
       "---\n",
       "\n",
       "**Is there anything specific about the Gaming Console Pro you'd like to know more about?** For example, I can help you with:\n",
       "- Return or warranty policies\n",
       "- Technical support for any issues\n",
       "- Information about compatible accessories\n",
       "- Other gaming products\n",
       "\n",
       "I also noticed from your profile that you're interested in low-latency headphones for competitive FPS gaming - I'd be happy to help you find the right gaming headphones to pair with your console!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session1 = str(uuid.uuid4())\n",
    "response, _ = invoke_agent_runtime(\n",
    "    \"I need information about the Gaming Console Pro. What are its specifications and price?\",\n",
    "    session1\n",
    ")\n",
    "print(\"Customer Query: Product information request\")\n",
    "display(Markdown(response[\"response\"].replace('\\\\n', '\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de72c8a-0ac8-40af-9604-b5a730ef803d",
   "metadata": {},
   "source": [
    "#### Test Scenario 2: Technical Support Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f903cc1-e025-4a67-bfeb-eed6b8f6f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using JWT authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: Technical support request\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Great! I found some troubleshooting guidance. Here are the **steps to troubleshoot your laptop startup issue**:\n",
       "\n",
       "## Power Issues Troubleshooting\n",
       "\n",
       "**Step 1: Check Power Connection**\n",
       "- Verify the power cable is firmly connected to both the laptop and the power outlet\n",
       "- Look for any visible damage to the power cable or connector\n",
       "\n",
       "**Step 2: Verify Power Outlet**\n",
       "- Try plugging the power cable into a different power outlet to ensure the original outlet is working\n",
       "- Test with a device you know works (like a lamp) to confirm the outlet has power\n",
       "\n",
       "**Step 3: Try a Different Power Cable**\n",
       "- If available, borrow or use an alternative power cable that's compatible with your laptop\n",
       "- This helps determine if the power supply is faulty\n",
       "\n",
       "**Step 4: Check for Physical Damage**\n",
       "- Inspect your laptop for any signs of physical damage, water damage, or loose components\n",
       "- Look at the charging port for corrosion or debris\n",
       "\n",
       "## Additional Information\n",
       "\n",
       "Since you have a ThinkPad, these general steps should apply to your model as well.\n",
       "\n",
       "**What I need to know to help further:**\n",
       "- Does your laptop show ANY signs of power (lights, fans, screen activity)?\n",
       "- Is the power LED indicator lighting up?\n",
       "- Any sounds or signs of activity when you press the power button?\n",
       "\n",
       "Once you provide these details, I can guide you through more specific troubleshooting steps. If the issue persists after these checks, it may require professional technical support.\n",
       "\n",
       "**Is there anything else I can help you with?**\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session2 = str(uuid.uuid4())\n",
    "response, _ = invoke_agent_runtime(\n",
    "    \"My laptop won't start up. Can you help me troubleshoot this issue?\",\n",
    "    session2\n",
    ")\n",
    "print(\"Customer Query: Technical support request\")\n",
    "display(Markdown(response[\"response\"].replace('\\\\n', '\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d85101-dd53-40a0-8d42-403742c7eed3",
   "metadata": {},
   "source": [
    "#### Test Scenario 3: Return Policy Inquiry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fc5937-b248-47bc-a596-48f46728bb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using JWT authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: Return policy inquiry\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Great news! Here's our **smartphone return policy**:\n",
       "\n",
       "**Return Window:** 30 days from delivery\n",
       "\n",
       "**Conditions for Returns:**\n",
       "- Device must be in original packaging\n",
       "- No physical damage\n",
       "- Factory reset required\n",
       "\n",
       "**Return Process:** You can initiate a return through:\n",
       "- Our online RMA (Return Merchandise Authorization) portal, or\n",
       "- Our technical support team\n",
       "\n",
       "**Shipping:** Free return shipping with a prepaid label provided\n",
       "\n",
       "**Refund Timeline:** 5-7 business days after we inspect the device\n",
       "\n",
       "**Warranty:** Your smartphone includes a 1-year manufacturer warranty\n",
       "\n",
       "Since you purchased it last week, you're well within the 30-day return window. Before initiating a return, would you like me to help troubleshoot the issue? Sometimes problems can be resolved quickly without needing a return. Could you tell me more about what's not working properly with your phone? \n",
       "\n",
       "Is it the overheating issue you mentioned, or something else? I'm here to help! üì±\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session3 = str(uuid.uuid4())\n",
    "response, _ = invoke_agent_runtime(\n",
    "    \"I bought a smartphone last week but it's not working properly. What's your return policy?\",\n",
    "    session3\n",
    ")\n",
    "print(\"Customer Query: Return policy inquiry\")\n",
    "display(Markdown(response[\"response\"].replace('\\\\n', '\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4bbc31-8f9c-4685-9db4-e59a500c78f3",
   "metadata": {},
   "source": [
    "#### Test Scenario 4: Complex Multi-Tool Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using JWT authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: Complex multi-tool request\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Great! I've gathered information for you. Here's what I found:\n",
       "\n",
       "## **Warranty Status - ‚ö†Ô∏è Important News**\n",
       "Your Gaming Console Pro warranty **has expired**:\n",
       "- **Serial Number:** MNO33333333\n",
       "- **Purchase Date:** November 25, 2023\n",
       "- **Warranty End Date:** November 25, 2024\n",
       "- **Status:** Expired (418 days ago)\n",
       "- **Warranty Type:** Gaming Warranty\n",
       "- **Original Coverage:** Controller issues, overheating protection, and hard drive replacement\n",
       "\n",
       "Since your warranty has expired, repair services may now have associated costs. However, I'd recommend contacting our support team to discuss extended warranty options or repair service pricing.\n",
       "\n",
       "---\n",
       "\n",
       "## **Technical Support - Connection Issues**\n",
       "\n",
       "Here are the recommended troubleshooting steps for connection problems:\n",
       "\n",
       "### **Wi-Fi Connection Issues:**\n",
       "1. Restart both your router and Gaming Console Pro\n",
       "2. Verify your Wi-Fi password is entered correctly\n",
       "3. Update your network drivers\n",
       "4. Reset network settings if problems persist\n",
       "5. Move closer to your router and check for interference\n",
       "\n",
       "### **Bluetooth Pairing Issues:**\n",
       "1. Clear your Bluetooth cache\n",
       "2. Remove and re-pair your devices\n",
       "3. Verify device compatibility\n",
       "4. Update your Bluetooth drivers\n",
       "5. Ensure both devices are in pairing mode\n",
       "\n",
       "---\n",
       "\n",
       "**Could you provide more specific details about your connection issue?** For example:\n",
       "- Are you having Wi-Fi or Bluetooth problems?\n",
       "- Can you not connect at all, or is the connection dropping?\n",
       "- Are there any error messages you're seeing?\n",
       "\n",
       "This will help me provide more targeted troubleshooting steps. I'm here to help! üéÆ\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session4 = str(uuid.uuid4())\n",
    "response, _ = invoke_agent_runtime(\n",
    "    \"I need help with my Gaming Console Pro. First, can you tell me about its warranty? Then I need technical support for connection issues.\",\n",
    "    session4\n",
    ")\n",
    "print(\"Customer Query: Complex multi-tool request\")\n",
    "display(Markdown(response[\"response\"].replace('\\\\n', '\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2d3e4-f5g6-h789-i012-j345k678l901",
   "metadata": {},
   "source": [
    "#### Test Scenario 5: General Capability Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "m2n3o4p5-q6r7-s890-t123-u456v789w012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using JWT authentication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Query: Capability inquiry\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"\n",
       "\n",
       "I'm happy to help! Here's a comprehensive overview of my available tools and capabilities:\n",
       "\n",
       "## üìã Available Tools & Capabilities\n",
       "\n",
       "### 1. **Product Information** (`get_product_info`)\n",
       "- Get detailed technical specifications for electronics\n",
       "- Access warranty information and features\n",
       "- Review product policies and capabilities\n",
       "- **Supported categories:** laptops, smartphones, headphones, monitors, and other electronics\n",
       "\n",
       "### 2. **Return & Warranty Policies** (`get_return_policy`)\n",
       "- Check return timeframes and conditions\n",
       "- Understand warranty coverage details\n",
       "- Review return procedures for specific product categories\n",
       "- **Coverage:** smartphones, laptops, accessories, and more\n",
       "\n",
       "### 3. **Technical Support** (`get_technical_support`)\n",
       "- Get assistance with technical issues and troubleshooting\n",
       "- Receive guidance for hardware or software problems\n",
       "- Access technical solutions for various devices\n",
       "\n",
       "### 4. **Warranty Status Check** (`LambdaUsingSDK___check_warranty_status`)\n",
       "- Verify warranty coverage using serial numbers\n",
       "- Optional email verification for account confirmation\n",
       "- Check warranty expiration and coverage details\n",
       "\n",
       "### 5. **Web Search** (`LambdaUsingSDK___web_search`)\n",
       "- Search for updated technical documentation\n",
       "- Access current product information\n",
       "- Find the latest specifications and compatibility details\n",
       "- Support for multiple regions\n",
       "\n",
       "## üéØ How I Can Help You\n",
       "\n",
       "‚úÖ Answer questions about product specifications and features  \n",
       "‚úÖ Explain warranty and return policies  \n",
       "‚úÖ Troubleshoot technical issues  \n",
       "‚úÖ Check warranty status on your devices  \n",
       "‚úÖ Find updated technical documentation  \n",
       "‚úÖ Provide recommendations based on your needs  \n",
       "\n",
       "Given your profile, I can particularly assist with:\n",
       "- **Gaming headphones** with low latency specifications\n",
       "- **Linux-compatible laptops** recommendations\n",
       "- **CPU installation documentation** and technical guidance\n",
       "- Gaming peripheral support\n",
       "\n",
       "**What can I help you with today?** Feel free to ask about products, technical issues, policies, or any other electronics support needs! üéÆüíª\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session5 = str(uuid.uuid4())\n",
    "response, _ = invoke_agent_runtime(\n",
    "    \"What kind of support can you provide? List all your available tools and capabilities.\",\n",
    "    session5\n",
    ")\n",
    "print(\"Customer Query: Capability inquiry\")\n",
    "display(Markdown(response[\"response\"].replace('\\\\n', '\\n')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3y4z5a6-b7c8-d901-e234-f567g890h123",
   "metadata": {},
   "source": [
    "### Step 6: Monitor Evaluation Results\n",
    "\n",
    "Monitor evaluation results through the AgentCore Observability console. Results may take a few minutes to appear as the system processes traces and applies evaluators.\n",
    "\n",
    "#### Accessing the Dashboard\n",
    "\n",
    "1. Navigate to the [AgentCore Observability console](https://console.aws.amazon.com/cloudwatch/home#gen-ai-observability/agent-core/agents)\n",
    "2. Find your customer support agent in the agents list\n",
    "3. Click on the `DEFAULT` endpoint to view evaluation metrics\n",
    "4. Look for the evaluation scores in the traces and sessions views\n",
    "\n",
    "#### What You'll See\n",
    "\n",
    "The dashboard will show:\n",
    "- **Goal Success Rate**: How well the agent achieves customer objectives\n",
    "- **Correctness**: Accuracy of information provided\n",
    "- **Tool Selection Accuracy**: Appropriate tool choices for queries\n",
    "\n",
    "![Online Evaluation Dashboard](images/online_evaluations_dashboard.png)\n",
    "\n",
    "*Evaluation metrics displayed in the AgentCore Observability dashboard*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i4j5k6l7-m8n9-o012-p345-q678r901s234",
   "metadata": {},
   "source": [
    "### Step 7: Understanding Evaluation Metrics\n",
    "\n",
    "**Goal Success Rate** measures whether the agent successfully addresses the customer's primary intent. High scores indicate effective problem-solving; low scores suggest unmet needs, incomplete responses, or misunderstood requests.\n",
    "\n",
    "**Correctness** evaluates factual accuracy of responses. High scores indicate accurate and reliable information; low scores suggest incorrect facts, outdated information, or misleading guidance.\n",
    "\n",
    "**Tool Selection Accuracy** evaluates whether the agent chooses appropriate tools for each task. High scores indicate proper tool selection; low scores suggest wrong tools, unnecessary calls, or missing tool usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v5w6x7y8-z9a0-b123-c456-d789e012f345",
   "metadata": {},
   "source": [
    "### Step 8: Analyzing Results and Next Steps\n",
    "\n",
    "**For Low Goal Success Rates:** Refine the agent's system prompt, improve tool descriptions and parameters, and add specific training examples.\n",
    "\n",
    "**For Low Correctness Scores:** Update the knowledge base with current information, improve fact-checking mechanisms, and review tool responses.\n",
    "\n",
    "**For Tool-Related Issues:** Refine tool parameter schemas, improve tool selection logic, and enhance tool documentation.\n",
    "\n",
    "**Continuous Monitoring:** Set up CloudWatch alarms for evaluation metrics, create dashboards for trend analysis, and implement automated alerts for quality degradation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g6h7i8j9-k0l1-m234-n567-o890p123q456",
   "metadata": {},
   "source": [
    "### Step 9: Clean Up (Optional)\n",
    "\n",
    "Disable the online evaluation configuration if needed by uncommenting the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "r7s8t9u0-v1w2-x345-y678-z901a234b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you want to disable the evaluation configuration\n",
    "# eval_client.delete_online_config(config_id=response['onlineEvaluationConfigId'])\n",
    "# print(\"Online evaluation configuration disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f1-g2h3-i456-j789-k012l345m678",
   "metadata": {},
   "source": [
    "### Congratulations! üéâ\n",
    "\n",
    "You have successfully completed **Lab 5: AgentCore Evaluations - Online Evaluation!**\n",
    "\n",
    "### What You Accomplished\n",
    "\n",
    "You configured automatic continuous online evaluation for your customer support agent with built-in evaluators assessing Goal Success Rate (customer satisfaction and problem resolution), Correctness (factual accuracy), and Tool Selection Accuracy (proper tool usage). Evaluation results are integrated with AgentCore Observability dashboards for real-time insights.\n",
    "\n",
    "**Key Benefits:** Proactive quality assurance catches issues before customer impact, data-driven optimization guides improvements, production confidence through performance monitoring at scale, and continuous learning identifies patterns and opportunities.\n",
    "\n",
    "**Next Steps:** Monitor your evaluation dashboard regularly, set up CloudWatch alarms for quality thresholds, use insights to iteratively improve your agent, and consider adding custom evaluators for domain-specific metrics.\n",
    "\n",
    "### Next Up: [Lab 6: Build User Interface ‚Üí](lab-06-frontend.ipynb)\n",
    "\n",
    "Complete the customer experience by building a user-friendly web interface for customers to interact with your quality-monitored agent.\n",
    "\n",
    "Your customer support agent is now production-ready with comprehensive quality monitoring! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
